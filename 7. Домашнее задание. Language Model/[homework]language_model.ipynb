{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot3c4fjZwC4T"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2JdzEXmwRU5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMohh_6CwC4W"
   },
   "source": [
    "### Задача определения частей речи, Part-Of-Speech Tagger (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Aad2tmBwC4Y"
   },
   "source": [
    "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gYYV0mdmwC4f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict, deque\n",
    "from nltk.corpus import brown\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPgI52lRwC4n"
   },
   "source": [
    "Вам в помощь http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxdJxMEAwC4o"
   },
   "source": [
    "Загрузим brown корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZvhXAL_9wC4q",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/arsen/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wto8PSC6wC4v"
   },
   "source": [
    "<b>Существует не одна система тегирования, поэтому будьте внимательны, когда прогнозируете тег слов в тексте и вычисляете качество прогноза. Можете получить несправедливо низкое качество вашего решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJ6tuHA_wC4z"
   },
   "source": [
    "Сейчас будем использовать универсальную систему тегирования universal_tagset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cht7dImWwC42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/arsen/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiTimRRywC47"
   },
   "source": [
    "<img src=\"https://4.bp.blogspot.com/-IcFli2wljs0/WrVCw3umY_I/AAAAAAAACYM/UJ_neoUAs3wF95dj2Ouf3BzxXzB_b2TbQCLcBGAs/s1600/postags.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyDBMcBSwC48"
   },
   "source": [
    "Мы имеем массив предложений пар (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BobflewQwC4-",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "brown_tagged_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSu1KqRrwC5L"
   },
   "source": [
    "Первое предложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zCHCZPlkwC5N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('County', 'NOUN'),\n",
       " ('Grand', 'ADJ'),\n",
       " ('Jury', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('Friday', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('investigation', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " (\"Atlanta's\", 'NOUN'),\n",
       " ('recent', 'ADJ'),\n",
       " ('primary', 'NOUN'),\n",
       " ('election', 'NOUN'),\n",
       " ('produced', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('no', 'DET'),\n",
       " ('evidence', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('that', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('irregularities', 'NOUN'),\n",
       " ('took', 'VERB'),\n",
       " ('place', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIV2MiRxwC5Q"
   },
   "source": [
    "Все пары (слово-тег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dVx9e9HcwC5R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_tagged_words = brown.tagged_words(tagset='universal')\n",
    "brown_tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-ADby6LwC5V"
   },
   "source": [
    "Проанализируйте данные, с которыми Вы работаете. Используйте `nltk.FreqDist()` для подсчета частоты встречаемости тега и слова в нашем корпусе. Под частой элемента подразумевается кол-во этого элемента в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JzRoXuKFcMZK",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Приведем слова к нижнему регистру\n",
    "brown_tagged_words = list(map(lambda x: (x[0].lower(), x[1]), brown_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4giWaqXjwC5W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во предложений:  57340\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во предложений: ', len(brown_tagged_sents))\n",
    "tags = [tag for (word, tag) in brown_tagged_words] # наши теги\n",
    "words = [word for (word, tag) in brown_tagged_words] # наши слова\n",
    "\n",
    "tag_num = pd.Series(nltk.FreqDist(tags)).sort_values(ascending=False) # тег - кол-во тега в корпусе\n",
    "word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False) # слово - кол-во слова в корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yfiPpCcLwC5Z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN    275558\n",
       "VERB    182750\n",
       ".       147565\n",
       "ADP     144766\n",
       "DET     137019\n",
       "ADJ      83721\n",
       "ADV      56239\n",
       "PRON     49334\n",
       "CONJ     38151\n",
       "PRT      29829\n",
       "NUM      14874\n",
       "X         1386\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8Y1huw7TwC5b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(tag_num.index, tag_num.values)\n",
    "plt.title(\"Tag_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gBbhnJsmwC5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    69971\n",
       ",      58334\n",
       ".      49346\n",
       "of     36412\n",
       "and    28853\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1WmEOBMkwC5i"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(word_num.index[:10], word_num.values[:10])\n",
    "plt.title(\"Word_frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n08z2PjMwC5o"
   },
   "source": [
    "### Вопрос 1:\n",
    "* Кол-во слова `cat` в корпусе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jhB7di3YwC5p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_num['cat'] # 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsCfVLsewC5s"
   },
   "source": [
    "### Вопрос 2:\n",
    "* Самое популярное слово с самым популярным тегом? <br>(*сначала выбираете слова с самым популярным тегом, а затем выбираете самое популярное слово из уже выбранных*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oio-XBYkwC5t",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n"
     ]
    }
   ],
   "source": [
    "tag = tag_num.index[0] # noun\n",
    "nouns = [i[0] for i in brown_tagged_words if i[1]==tag]\n",
    "series = pd.Series(nltk.FreqDist(nouns)).sort_values(ascending=False)\n",
    "answer = series.index[0] # time\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-OGc1rSwC5x"
   },
   "source": [
    "Впоследствии обучение моделей может занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eb7MhxVRwC5y"
   },
   "source": [
    "Категории нашего корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GSiVcP1TwC51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjSlFatJwC53"
   },
   "source": [
    "Будем работать с категорией humor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f1rl5x0wC55"
   },
   "source": [
    "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GX9t-1qowC58"
   },
   "outputs": [],
   "source": [
    "#brown_tagged_sents = brown.tagged_sents(tagset=\"universal\", categories='humor')\n",
    "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
    "# Приведем слова к нижнему регистру\n",
    "my_brown_tagged_sents = []\n",
    "for sent in brown_tagged_sents:\n",
    "    my_brown_tagged_sents.append(list(map(lambda x: (x[0].lower(), x[1]), sent)))\n",
    "my_brown_tagged_sents = np.array(my_brown_tagged_sents)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sents, test_sents = train_test_split(my_brown_tagged_sents, random_state=0, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pXkVwUjYwC5-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51606"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JQMjzJ2YwC6C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5734"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rEasLVcwC6G"
   },
   "source": [
    "### Метод максимального правдоподобия для обучения модели\n",
    "\n",
    "* $\\normalsize S = s_0, s_1, ..., s_N$ - скрытые состояния, то есть различные теги\n",
    "* $\\normalsize O = o_0, o_1, ..., o_M$ - различные слова\n",
    "* $\\normalsize a_{i,j} = p(s_j|s_i)$ - вероятность того, что, находясь в скрытом состоянии $s_i$, мы попадем в состояние $s_j$ (элемент матрицы $A$)\n",
    "* $\\normalsize b_{k,j}=p(o_k|s_j)$ - вероятность того, что при скрытом состоянии $s_j$ находится слово $o_k$(элемент матрицы $B$)\n",
    "\n",
    "$$\\normalsize x_t \\in O, y_t \\in S$$\n",
    "$\\normalsize (x_t, y_t)$ - слово и тег, стоящие на месте $t$ $\\Rightarrow$ \n",
    "* $\\normalsize X$ - последовательность слов\n",
    "* $\\normalsize Y$ - последовательность тегов\n",
    "\n",
    "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
    "\n",
    "- Вероятности переходов между скрытыми состояниями $p(y_t | y_{t - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
    "\n",
    "\n",
    "- Вероятности эмиссий наблюдаемых состояний $p(x_t | y_t)$ посчитайте на основе частот \"POS-тег - слово\".\n",
    "\n",
    "\n",
    "- Распределение вероятностей начальных состояний $p(y_0)$ задайте равномерным.\n",
    "\n",
    "Пример $X = [x_0, x_1], Y = [y_0, y_1]$:<br><br>\n",
    "$$p(X, Y) = p(x_0, x_1, y_0, y_1) = p(y_0) \\cdot p(x_0, x_1, y_1 | y_0) = p(y_0) \\cdot p(x_0 | y_0) \\cdot\n",
    "p(x_1, y_1 | x_0, y_0) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | x_0, y_0) \\cdot p(x_1 | x_0, y_0, y_1)\n",
    "= (\\text{в силу условий нашей модели}) = \\\\ = p(y_0) \\cdot p(x_0 | y_0) \\cdot p(y_1 | y_0) \\cdot p(x_1 | y_1) \\Rightarrow$$ <br>\n",
    "Для последовательности длины $n + 1$:<br>\n",
    "$$p(X, Y) = p(x_0 ... x_{n - 1}, y_0 ... y_{n - 1}) \\cdot p(y_n | y_{n - 1}) \\cdot p(x_n | y_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tysPoe5rwC6I"
   },
   "source": [
    "#### Алгоритм Витерби для применения модели\n",
    "\n",
    "\n",
    "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
    "\n",
    "$$ \\hat{Y} = \\arg \\max_{Y} p(Y|X) = \\arg \\max_{Y} p(Y, X) $$\n",
    "\n",
    "Пусть $\\normalsize Q_{t,s}$ - самая вероятная последовательность скрытых состояний длины $t$ с окончанием в состоянии $s$. $\\normalsize q_{t, s}$ - вероятность этой последовательности.\n",
    "$$(1)\\: \\normalsize q_{t,s} = \\max_{s'} q_{t - 1, s'} \\cdot p(s | s') \\cdot p(o_t | s)$$\n",
    "$\\normalsize Q_{t,s}$ можно восстановить по argmax-ам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QpEXdhOfwC6J"
   },
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:    \n",
    "    def __init__(self):\n",
    "    \n",
    "        pass\n",
    "        \n",
    "    def fit(self, train_tokens_tags_list):\n",
    "        \"\"\"\n",
    "        train_tokens_tags_list: массив предложений пар слово-тег (выборка для train) \n",
    "        \"\"\"\n",
    "        tags = [tag for sent in train_tokens_tags_list\n",
    "                for (word, tag) in sent]\n",
    "        words = [word for sent in train_tokens_tags_list\n",
    "                 for (word, tag) in sent]\n",
    "        \n",
    "        tag_num = pd.Series(nltk.FreqDist(tags)).sort_index()\n",
    "        word_num = pd.Series(nltk.FreqDist(words)).sort_values(ascending=False)\n",
    "        \n",
    "        most_popular_tag = tag_num.index[tag_num.argmax()] # noun\n",
    "        words_with_mpt = [word for sent in train_tokens_tags_list for (word, tag) in sent if tag==most_popular_tag]\n",
    "        series = pd.Series(nltk.FreqDist(words_with_mpt)).sort_values(ascending=False)\n",
    "        self.default_word = series.index[series.argmax()] # time\n",
    "\n",
    "        self.tags = tag_num.index\n",
    "        self.words = word_num.index\n",
    "        \n",
    "        A = pd.DataFrame({'{}'.format(tag) : [0] * len(tag_num) for tag in tag_num.index}, index=tag_num.index)\n",
    "        B = pd.DataFrame({'{}'.format(tag) : [0] * len(word_num) for tag in tag_num.index}, index=word_num.index)\n",
    "        \n",
    "        # Вычисляем матрицу A и B по частотам слов и тегов\n",
    "        # sent - предложение\n",
    "        # sent[i][0] - i слово в этом предложении, sent[i][1] - i тег в этом предложении\n",
    "        for sent in train_tokens_tags_list:\n",
    "            for i in range(len(sent)):\n",
    "                B.loc[sent[i][0],sent[i][1]] += 1 # текущая i-пара слово-тег (обновите матрицу B аналогично A)\n",
    "                if len(sent) - 1 != i: # для последнего тега нет следующего тега\n",
    "                    A.loc[sent[i][1], sent[i + 1][1]] += 1 # пара тег-тег\n",
    "                \n",
    "        \n",
    "        # переходим к вероятностям\n",
    "        \n",
    "        # нормируем по строке, то есть по всем всевозможным следующим тегам\n",
    "        A = A.divide(A.sum(axis=1), axis=0)\n",
    "        \n",
    "        # нормируем по столбцу, то есть по всем всевозможным текущим словам\n",
    "        B = B / np.sum(B, axis=0)\n",
    "        \n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def predict(self, test_tokens_list):\n",
    "        \"\"\"\n",
    "        test_tokens_list : массив предложений пар слово-тег (выборка для test)\n",
    "        \"\"\"\n",
    "        predict_tags = OrderedDict({i : np.array([]) for i in range(len(test_tokens_list))})\n",
    "        \n",
    "        for i_sent in range(len(test_tokens_list)):\n",
    "            \n",
    "            current_sent = test_tokens_list[i_sent] # текущее предложение\n",
    "            len_sent = len(current_sent) # длина предложения \n",
    "            \n",
    "            q = np.zeros(shape=(len_sent + 1, len(self.tags)))\n",
    "            q[0] = 1 # нулевое состояние (равномерная инициализация по всем s)\n",
    "            back_point = np.zeros(shape=(len_sent + 1, len(self.tags))) # # argmax\n",
    "            \n",
    "            for t in range(len_sent):\n",
    "                \n",
    "                # если мы не встречали такое слово в обучении, то вместо него будет \n",
    "                # самое популярное слово с самым популярным тегом (вопрос 2)\n",
    "                if current_sent[t] not in self.words:\n",
    "                    tag = tag_num.index[0] # noun\n",
    "                    \n",
    "                    nouns = [i[0] for i in brown_tagged_words if i[1]==tag]\n",
    "                    series = pd.Series(nltk.FreqDist(nouns)).sort_values(ascending=False)\n",
    "                    result = series.index[0]\n",
    "                    \n",
    "                    current_sent[t] = self.default_word\n",
    "                    \n",
    "                # через max выбираем следующий тег\n",
    "                for i_s in range(len(self.tags)):\n",
    "                    \n",
    "                    s = self.tags[i_s]\n",
    "                    \n",
    "                    # формула (1)\n",
    "                    q[t + 1][i_s] = np.max(q[t,:] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s])\n",
    "                    \n",
    "                    # argmax формула(1)\n",
    "                    \n",
    "                    # argmax, чтобы восстановить последовательность тегов\n",
    "                    back_point[t + 1][i_s] = (q[t,:] *\n",
    "                        self.A.loc[:, s] * \n",
    "                        self.B.loc[current_sent[t], s]).reset_index()[s].idxmax() # индекс \n",
    "                    \n",
    "            back_point = back_point.astype('int')\n",
    "            \n",
    "            # выписываем теги, меняя порядок на реальный\n",
    "            back_tag = deque()\n",
    "            current_tag = np.argmax(q[len_sent])\n",
    "            for t in range(len_sent, 0, -1):\n",
    "                back_tag.appendleft(self.tags[current_tag])\n",
    "                current_tag = back_point[t, current_tag]\n",
    "             \n",
    "            predict_tags[i_sent] = np.array(back_tag)\n",
    "        \n",
    "        \n",
    "        return predict_tags                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0BLgsWkwC6M"
   },
   "source": [
    "Обучите скрытую марковскую модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZcSoyUAxwC6M"
   },
   "outputs": [],
   "source": [
    "my_model = HiddenMarkovModel().fit(brown_tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeVNt19kwC6P"
   },
   "source": [
    "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
    "\n",
    "- 'He can stay'\n",
    "- 'a cat and a dog'\n",
    "- 'I have a television'\n",
    "- 'My favourite character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cMJErf7NwC6Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, array(['PRON', 'VERB', 'VERB'], dtype='<U4')),\n",
       "             (1, array(['DET', 'NOUN', 'CONJ', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (2, array(['PRON', 'VERB', 'DET', 'NOUN'], dtype='<U4')),\n",
       "             (3, array(['DET', 'NOUN', 'NOUN'], dtype='<U4'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [['He', 'can', 'stay'], ['a', 'cat', 'and', 'a', 'dog'], ['I', 'have', 'a', 'television'],\n",
    "         ['My', 'favourite', 'character']]\n",
    "my_model.predict(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suDCwbGMwC6T"
   },
   "source": [
    "### Вопрос 3:\n",
    "* Какой тег вы получили для слова `can`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ReHeG3IjwC6U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(sents)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObAslurlwC6X"
   },
   "source": [
    "### Вопрос 4:\n",
    "* Какой тег вы получили для слова `favourite`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "94crVrrXwC6Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(sents)[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPC4NZ4HwC6a"
   },
   "source": [
    "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-7aioBc1wC6b"
   },
   "outputs": [],
   "source": [
    "def accuracy_score(model, sents):\n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "\n",
    "    for sent in sents:\n",
    "        tags = [tag for (word,tag) in sent]\n",
    "        words = [word for (word,tag) in sent]\n",
    "        \n",
    "        outputs = model.predict([words])[0]\n",
    "\n",
    "        true_pred += np.sum(outputs==tags)\n",
    "        num_pred += len(outputs)\n",
    "    print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "roesKrPCcMbp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.4445848359613 %\n"
     ]
    }
   ],
   "source": [
    "# might take some time, hang in there\n",
    "accuracy = accuracy_score(my_model, test_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff_W7J8XwC6e"
   },
   "source": [
    "### Вопрос 5:\n",
    "* Какое качество вы получили(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ptvlpc-6wC6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpAgfZRTwC6h"
   },
   "source": [
    "## DefaultTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b4cPKyiwC6j"
   },
   "source": [
    "### Вопрос 6:\n",
    "* Какое качество вы бы получили, если бы предсказывали любой тег, как самый популярный тег на выборке train(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "pM28MT0gcMb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.47521651004238 %\n"
     ]
    }
   ],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "\n",
    "    #outputs = model.predict([words])[0]\n",
    "\n",
    "    true_pred += np.sum(['NOUN'] * len(words) == tags)\n",
    "    num_pred += len(words)\n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td-0Pe0vwC6k"
   },
   "source": [
    "Вы можете испоьзовать DefaultTagger(метод tag для предсказания частей речи предложения) или можете преобразовать код выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "NfZYlMxJwC6m"
   },
   "outputs": [],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "9CXKibo_cMcB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 23.47521651004238 %\n"
     ]
    }
   ],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "for sent in test_sents:\n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "    \n",
    "    tagged_sent = default_tagger.tag(words)\n",
    "    outputs = [tag for token, tag in tagged_sent]\n",
    "    \n",
    "    true_pred += np.sum(outputs == tags)\n",
    "    num_pred += len(words)\n",
    "    \n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz7Q3BfbwC6o"
   },
   "source": [
    "## Модель Стенфорда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKYPKJYLwC6p"
   },
   "source": [
    "Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. \n",
    "Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "yW-PR54QwC6p",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ:  ['PRON', 'VERB', 'DET', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tag.mapping import map_tag\n",
    "\n",
    "# используйте путь до jar и до model\n",
    "jar = './stanford-postagger.jar'\n",
    "model = './english-bidirectional-distsim.tagger'\n",
    "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "\n",
    "# проверим на предложении\n",
    "tagged_sent = stanford_tagger.tag(['I', 'bear', 'a', 'bag'])\n",
    "print('Ответ: ', [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1z8x4vvwC6s"
   },
   "source": [
    "### Вопрос 7:\n",
    "* Какое качество вы получили на модели Стенфорда(округлите до одного знака после запятой)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "GBd3RgqVwC6s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.45447440406409 %\n"
     ]
    }
   ],
   "source": [
    "true_pred = 0\n",
    "num_pred = 0\n",
    "\n",
    "# ~5k examples in test_sents, takes too long, model crashes\n",
    "for sent in test_sents[:500]:\n",
    "        \n",
    "    tags = np.array([tag for (word, tag) in sent])\n",
    "    words = np.array([word for (word, tag) in sent])\n",
    "    \n",
    "    tagged_sent = stanford_tagger.tag(words)\n",
    "    outputs = [map_tag('en-ptb', 'universal', tag) for token, tag in tagged_sent]\n",
    "    \n",
    "    true_pred += np.sum(outputs == tags)\n",
    "    num_pred += len(words)\n",
    "    \n",
    "print(\"Accuracy:\", true_pred / num_pred * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w1W5hSkcMcV"
   },
   "source": [
    "## BiLSTMTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm1-S3t2cMcW"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GayTl7mUcMcX"
   },
   "source": [
    "Изменим структуру данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnXcI64fxoj4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_data = [list(zip(*sent)) for sent in brown_tagged_sents]\n",
    "print(pos_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpRE3c-3cMcc"
   },
   "source": [
    "До этого мы писали много кода сами, теперь пора эксплуатировать pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvFlzrYnxokE"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "import torchtext\n",
    "\n",
    "# наши поля\n",
    "WORD = Field(lower=True)\n",
    "TAG = Field(unk_token=None) # все токены нам извсетны\n",
    "\n",
    "# создаем примеры\n",
    "examples = []\n",
    "for words, tags in pos_data:\n",
    "    examples.append(torchtext.data.Example.fromlist([list(words), list(tags)], fields=[('words', WORD), ('tags', TAG)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjl6u6cpOc1u"
   },
   "source": [
    "Вот один наш пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnrzktytN9rL"
   },
   "outputs": [],
   "source": [
    "print(vars(examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUhTrWCWcMcj"
   },
   "source": [
    "Теперь формируем наш датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGKkbZUIxokO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# кладем примеры в наш датасет\n",
    "dataset = torchtext.data.Dataset(examples, fields=[('words', WORD), ('tags', TAG)])\n",
    "\n",
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.1, 0.1])\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T89unpppcMcp"
   },
   "source": [
    "Построим словари. Параметр `min_freq` выберете сами. При построении словаря испольузем только **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZwkwhlrxoka",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WORD.build_vocab(train_data.words, min_freq=5)\n",
    "TAG.build_vocab(train_data.tags)\n",
    "\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(WORD.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TAG.vocab)}\")\n",
    "\n",
    "print(WORD.vocab.itos[:20])\n",
    "print(TAG.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjn07NP-xokl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxgkU4cZcMcz"
   },
   "source": [
    "Посмотрим с насколько большими предложениями мы имеем дело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVpMi1_0xoku",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "length = map(len, [vars(x)['words'] for x in train_data.examples])\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.title(\"Length distribution in Train data\")\n",
    "plt.hist(list(length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi28N2RBcMc5"
   },
   "source": [
    "Для обучения `BiLSTM` лучше использовать colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAGSrqWsxok2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DSWm0UjcMc-"
   },
   "source": [
    "Для более быстрого и устойчивого обучения сгруппируем наши данные по батчам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmwAyhNgxok_"
   },
   "outputs": [],
   "source": [
    "# бьем нашу выборку на батч, не забывая сначала отсортировать выборку по длине\n",
    "def _len_sort_key(x):\n",
    "    return len(x.words)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aTjW00nxolI"
   },
   "outputs": [],
   "source": [
    "# посморим  на количество батчей\n",
    "list(map(len, [train_iterator, valid_iterator, test_iterator]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyLQsizhcMdI"
   },
   "source": [
    "### Модель и её обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i9oHzcrcMdJ"
   },
   "source": [
    "Инициализируем нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff7BLWs_xolS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, dropout, bidirectional=False, lstm_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(embedding_dim=emb_dim, num_embeddings=input_dim) #'''your code'''\n",
    "        self.dropout = nn.Dropout(dropout)  #'''your code'''\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=lstm_layers, bidirectional=bidirectional) #'''your code'''\n",
    "        # если bidirectional, то предсказываем на основе конкатенации двух hidden\n",
    "        self.tag = nn.Linear((1 + bidirectional) * hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, sent):\n",
    "        \n",
    "        #sent = [sent len, batch size] \n",
    "        embedded = self.dropout(self.embeddings(sent)) # '''your code'''\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        output, _ = self.rnn(embedded) #'''your code'''\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        prediction = self.tag(output) #'''your code'''\n",
    "        #prediction = [sent len, batch_size, output_dim]\n",
    "        return prediction\n",
    "        \n",
    "# параметры модели\n",
    "INPUT_DIM = len(word_num) #'''your code'''\n",
    "OUTPUT_DIM = len(tag_num)+1 #'''your code'''\n",
    "EMB_DIM = 200 #'''your code'''\n",
    "HID_DIM = 16 #'''your code'''\n",
    "DROPOUT = 0.1 #'''your code'''\n",
    "BIDIRECTIONAL = True #'''your code'''\n",
    "LSTM_LAYERS = 3\n",
    "\n",
    "model = LSTMTagger(INPUT_DIM,EMB_DIM,HID_DIM,OUTPUT_DIM,DROPOUT,BIDIRECTIONAL,LSTM_LAYERS).to(device)\n",
    "\n",
    "# инициализируем веса\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJLqq8IHcMdQ"
   },
   "source": [
    "Подсчитаем количество обучаемых параметров нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Auu53Kdxolm"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters()) #'''your code'''\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSBfvf9HcMd9"
   },
   "source": [
    "Погнали обучать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjD1Y7Rmxolu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PAD_IDX = TAG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):Вопрос\n",
    "        \n",
    "        '''your code'''\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch.words)\n",
    "        tags = batch.tags\n",
    "        \n",
    "        #tags = [sent len, batch size]\n",
    "        #output = [sent len, batch size, output dim]\n",
    "        \n",
    "        output = output.view(-1, OUTPUT_DIM)\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        #tags = [sent len * batch size]\n",
    "        #output = [sent len * batch size, output dim]\n",
    "        loss = criterion(output, tags)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping(решение проблемы взрыва граденты), clip - максимальная норма вектора\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            \n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            output = model(batch.words)\n",
    "            tags = batch.tags\n",
    "\n",
    "            #tags = [sent len, batch size]\n",
    "            #output = [sent len, batch size, output dim]\n",
    "\n",
    "            output = output.view(-1, OUTPUT_DIM)\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            #tags = [sent len * batch size]\n",
    "            #output = [sent len * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, tags)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJdXIyTHxol2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 60\n",
    "CLIP = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-val-model.pt')\n",
    "\n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sDAfAq9xol9"
   },
   "outputs": [],
   "source": [
    "def accuracy_model(model, iterator):\n",
    "    model.eval()\n",
    "    \n",
    "    true_pred = 0\n",
    "    num_pred = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            \n",
    "            tags = batch.tags\n",
    "            output = model(batch.words)\n",
    "            \n",
    "            #output = [sent len, batch size, output dim]\n",
    "            _, output = output.max(2)\n",
    "            #output = [sent len, batch size]\n",
    "            predict_tags = output.cpu().numpy()\n",
    "            true_tags = tags.cpu().numpy()\n",
    "\n",
    "            true_pred += np.sum((true_tags == predict_tags) & (true_tags != PAD_IDX))\n",
    "            num_pred += np.prod(true_tags.shape) - (true_tags == PAD_IDX).sum()\n",
    "        \n",
    "    return round(true_pred / num_pred * 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2n0H85mxomE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_model(model, test_iterator), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FacTKSPJcMeP"
   },
   "source": [
    "Вы можете улучшить качество, изменяя параметры модели. Но чтобы добиться нужного качества, вам неообходимо взять все выборку, а не только категорию `humor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXqXg0gbcMeR"
   },
   "outputs": [],
   "source": [
    "#brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnpi2R6rcMeU"
   },
   "source": [
    "Вам неоходимо добиться качества не меньше, чем `accuracy = 92 %` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqD1lZuwxomK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = LSTMTagger(INPUT_DIM, EMB_DIM, HID_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL).to(device)\n",
    "best_model.load_state_dict(torch.load('best-val-model.pt'))\n",
    "assert accuracy_model(best_model, test_iterator) >= 92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVfdJM-lcMeZ"
   },
   "source": [
    "Пример решение нашей задачи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3GUbwldxomW"
   },
   "outputs": [],
   "source": [
    "def print_tags(model, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        words, _ = data\n",
    "        example = torch.LongTensor([WORD.vocab.stoi[elem] for elem in words]).unsqueeze(1).to(device)\n",
    "        \n",
    "        output = model(example).argmax(dim=-1).cpu().numpy()\n",
    "        tags = [TAG.vocab.itos[int(elem)] for elem in output]\n",
    "\n",
    "        for token, tag in zip(words, tags):\n",
    "            print(f'{token:15s}{tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mQoHc_EcMed",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_tags(model, pos_data[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zMIJDOBmwC6v"
   },
   "source": [
    "## Сравните результаты моделей HiddenMarkov, LstmTagger:\n",
    "* при обучение на маленькой части корпуса, например, на категории humor\n",
    "* при обучении на всем корпусе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDdsG2AjO-sp"
   },
   "source": [
    "# humor\n",
    "nn 60 epoh: 84% acc\n",
    "stanford: 92%\n",
    "hmm: 96.3\n",
    "\n",
    "# all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]language_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
