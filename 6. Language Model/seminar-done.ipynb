{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install nltk gdown seaborn torchtext pymorphy2 gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар: Language Model\n",
    "\n",
    "Привет! Сегодня мы создадим свою Language Model! Посмотрим на три вида моделей: N-gram, CNN, LSTM. Для обучения LM лучше всего подходят большие корпуса с разнообразными текстами: от новостей до художственной литературы. Для русского языка есть большой корпус [Taiga](https://tatianashavrina.github.io/taiga_site/). Для английского используют тексты из [википедии](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/) или [BookCorpus](https://github.com/soskek/bookcorpus). \n",
    "\n",
    "Сегодня вы возьмем маленькую часть датасета Taiga: новости с сайта [nplus1](https://nplus1.ru). Каждая новость на сайте помечается меткой сложности (от 0 до 10). Это не поможет нам с обучением хорошей LM, но даст возможность поиграться с генерацией текста.\n",
    "\n",
    "Загрузим датасет и подготовим его к работе!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1UtF9urwAL2OiMg7N5iFmZmeiRzq1Psw6\n",
      "To: /home/adchumachenko/dls/lm/nplus1.zip\n",
      "49.8MB [00:02, 17.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nplus1.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "\n",
    "gdown.download(\"https://drive.google.com/uc?id=1UtF9urwAL2OiMg7N5iFmZmeiRzq1Psw6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  nplus1.zip\n",
      "replace nplus1/newmetadata.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip nplus1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newmetadata.csv  texts\ttexts_tagged\r\n"
     ]
    }
   ],
   "source": [
    "!ls nplus1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся информация про тексты содержится в таблице `newmetadata.csv`. Загрузим её с помощью `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>textid</th>\n",
       "      <th>textname</th>\n",
       "      <th>textregion</th>\n",
       "      <th>textrubric</th>\n",
       "      <th>textdiff</th>\n",
       "      <th>author</th>\n",
       "      <th>authortexts</th>\n",
       "      <th>authorreaders</th>\n",
       "      <th>magazine</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tags</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nplus1</td>\n",
       "      <td>20151029radar</td>\n",
       "      <td>Французы испытали пассивный «летающий радар»</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Оружие</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Василий Сычев</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29 Окт. 2015</td>\n",
       "      <td>16:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nplus1.ru/news/2015/10/29/radar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nplus1</td>\n",
       "      <td>20161212aggressive-drones</td>\n",
       "      <td>Для агрессивных маневров дронам хватило камеры...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Технологии</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Николай Воронцов</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12 Дек. 2016</td>\n",
       "      <td>17:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nplus1.ru/news/2016/12/12/aggressive-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nplus1</td>\n",
       "      <td>20150826twinjet-hubble</td>\n",
       "      <td>«Хаббл» получил новые фотографии «крыльев» Баб...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Технологии</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26 Авг. 2015</td>\n",
       "      <td>17:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nplus1.ru/news/2015/08/26/twinjet-hubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nplus1</td>\n",
       "      <td>20150826shining-solved-profile</td>\n",
       "      <td>Криминологи научились вычислять будущих бытовы...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26 Авг. 2015</td>\n",
       "      <td>14:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nplus1.ru/news/2015/08/26/shining-solv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nplus1</td>\n",
       "      <td>20160111snow</td>\n",
       "      <td>Ford начал снежные испытания беспилотного авто...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Василий Сычев</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11 Янв. 2016</td>\n",
       "      <td>09:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nplus1.ru/news/2016/01/11/snow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  segment                          textid  \\\n",
       "0  nplus1                   20151029radar   \n",
       "1  nplus1       20161212aggressive-drones   \n",
       "2  nplus1          20150826twinjet-hubble   \n",
       "3  nplus1  20150826shining-solved-profile   \n",
       "4  nplus1                    20160111snow   \n",
       "\n",
       "                                            textname  textregion  textrubric  \\\n",
       "0       Французы испытали пассивный «летающий радар»         NaN      Оружие   \n",
       "1  Для агрессивных маневров дронам хватило камеры...         NaN  Технологии   \n",
       "2  «Хаббл» получил новые фотографии «крыльев» Баб...         NaN  Технологии   \n",
       "3  Криминологи научились вычислять будущих бытовы...         NaN         NaN   \n",
       "4  Ford начал снежные испытания беспилотного авто...         NaN   Транспорт   \n",
       "\n",
       "   textdiff            author  authortexts  authorreaders  magazine  \\\n",
       "0       2.1     Василий Сычев          NaN            NaN       NaN   \n",
       "1       2.6  Николай Воронцов          NaN            NaN       NaN   \n",
       "2       1.1               NaN          NaN            NaN       NaN   \n",
       "3       4.4               NaN          NaN            NaN       NaN   \n",
       "4       1.7     Василий Сычев          NaN            NaN       NaN   \n",
       "\n",
       "           date   time  tags  \\\n",
       "0  29 Окт. 2015  16:47   NaN   \n",
       "1  12 Дек. 2016  17:27   NaN   \n",
       "2  26 Авг. 2015  17:46   NaN   \n",
       "3  26 Авг. 2015  14:15   NaN   \n",
       "4  11 Янв. 2016  09:44   NaN   \n",
       "\n",
       "                                              source  \n",
       "0            https://nplus1.ru/news/2015/10/29/radar  \n",
       "1  https://nplus1.ru/news/2016/12/12/aggressive-d...  \n",
       "2   https://nplus1.ru/news/2015/08/26/twinjet-hubble  \n",
       "3  https://nplus1.ru/news/2015/08/26/shining-solv...  \n",
       "4             https://nplus1.ru/news/2016/01/11/snow  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "metadata = pd.read_table(\"nplus1/newmetadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колонка `textdiff` содержит информацию про сложность текста. Чтобы выделить нужный кусок, воспользуемся методами `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[(metadata[\"textdiff\"] > 4) & (metadata[\"textdiff\"] < 5)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение сложности текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6b716de470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "sns.set()\n",
    "sns.histplot(metadata[\"textdiff\"], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предобученные эмбеддинги, которые готовы к работе с русским языком ([весь список](https://rusvectores.org/ru/models/)). Из-за особенностей русского языка эмбеддинги ожидают строку вида `{слово}_{часть речи}`. Надо про это помнить при работе с этими эмбеддингами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import downloader as api\n",
    "\n",
    "word2vec = api.load('word2vec-ruscorpora-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим датасет к работе с моделями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "\n",
    "PAD = \"<PAD>\"\n",
    "EOS = \"<EOS>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, min_diff=0, max_diff=10):\n",
    "        self.root = Path(\"nplus1/texts\")\n",
    "        metadata = pd.read_table(\"nplus1/newmetadata.csv\")\n",
    "        self.metadata = metadata[(metadata[\"textdiff\"] > min_diff) & (metadata[\"textdiff\"] <= max_diff)]\n",
    "        \n",
    "        # Получим список всех текстов и сверим его с таблицей\n",
    "        file_paths = np.array(list(self.root.glob(\"*.txt\")))\n",
    "        text_ids = np.array(list(path.name.split(\".\")[0] for path in file_paths))\n",
    "        self.text_ids = text_ids[np.isin(text_ids, self.metadata[\"textid\"])]\n",
    "        self.file_paths = file_paths[np.isin(text_ids, self.metadata[\"textid\"])]\n",
    "        \n",
    "        self.min_diff = min_diff\n",
    "        self.max_diff = max_diff\n",
    "        \n",
    "        self.tokenizer = nltk.WordPunctTokenizer()\n",
    "        self.morph = MorphAnalyzer()\n",
    "        \n",
    "        self.token2idx = {PAD: 0, EOS: 1, UNK: 2}\n",
    "        self.vocab = set([PAD, EOS, UNK])\n",
    "        for path in tqdm(self.file_paths):\n",
    "            with open(path) as file:\n",
    "                text = file.read()\n",
    "                self.vocab.update([token for token in self.tokenize_(text) if token not in (UNK, PAD, EOS)]) # добавь токены в словарь\n",
    "        self.token2idx.update({t:num + 3 for num, t in enumerate(self.vocab) if t not in (UNK, PAD, EOS)})\n",
    "        self.idx2token = {num: token for token, num in self.token2idx.items()}\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        with open(self.file_paths[item]) as file:\n",
    "            text = file.read()\n",
    "            \n",
    "        tokens = self.tokenize_(text)\n",
    "        \n",
    "        text_id = self.text_ids[item]\n",
    "        textdiff = self.metadata[self.metadata[\"textid\"] == text_id][\"textdiff\"]\n",
    "        \n",
    "        # для обучение нейронок нам потребуются индексы токенов в словаре.\n",
    "        input_ids = [self.token2idx[token] for token in tokens]\n",
    "        \n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"tokens\": tokens,\n",
    "            \"textdiff\": textdiff,\n",
    "            \"input_ids\": input_ids\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def tokenize_(self, text):\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        morphs = [self.morph.parse(token)[0]\n",
    "                  for token in tokens \n",
    "                  if (token not in string.punctuation)]\n",
    "        tokens = [f\"{morph.normal_form}_{morph.tag.POS}\" for morph in morphs]\n",
    "        tokens = [token for token in tokens if token in word2vec]\n",
    "        tokens += [EOS]\n",
    "        return tokens\n",
    "    \n",
    "    def embeddins(self):\n",
    "        w = torch.rand(len(self.vocab) + 1, word2vec.vector_size)\n",
    "        for token, num in self.token2idx.items():\n",
    "            if token in word2vec:\n",
    "                w[num] = torch.from_numpy(word2vec[token])\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61803e84f194485baa965524bcbcaf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1846.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = TextDataset(0.5, 2)\n",
    "train_size = np.ceil(len(dataset) * 0.8).astype(int)\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. N-gram LM\n",
    "\n",
    "Первая жертва – N-граммная модель. Она пишется скучно, но хорошо работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class NGramModel(object):\n",
    "    '''\n",
    "    Структура этой реализации n-граммной модели следующая:\n",
    "    self.ngrams – словарь, который на каждый (token_0, ..., token_(n-1)) – n-1 tuple из токенов\n",
    "        хранит частоту появления следующего токена. Для подсчета числа токенов воспользуемся\n",
    "        Counter\n",
    "    self.tokenize_func – функция токенизации текста. С её помощью будем получать токены.\n",
    "    '''\n",
    "    def __init__(self, n=2):\n",
    "        self.ngrams = defaultdict(Counter)\n",
    "        self.n = n\n",
    "        self.tokenize_func = None\n",
    "        \n",
    "    def compute_ngrams(self, dataset, tokenize_func):\n",
    "        self.tokenize_func = tokenize_func\n",
    "        self.ngrams = defaultdict(Counter)\n",
    "        for row in tqdm(dataset):\n",
    "            ngram = [PAD] * self.n\n",
    "            for token in row[\"tokens\"]:\n",
    "                ngram[:-1] = ngram[1:]\n",
    "                ngram[-1] = token\n",
    "                self.ngrams[tuple(ngram[:-1])].update([ngram[-1]])\n",
    "            \n",
    "    def get_log_probs(self, prefix, min_log_pr=-15):\n",
    "        '''\n",
    "        Функция, которая будет возвращать логарифмы частот появления токенов\n",
    "        '''\n",
    "        if isinstance(prefix, str):\n",
    "            # преврати строку в tuple из токенов с помощью tokenize_func. \n",
    "            prefix = self.tokenize_func(prefix)[:-1]\n",
    "        if len(prefix) < self.n - 1:\n",
    "            prefix = [PAD] * (self.n - len(prefix) - 1) + prefix\n",
    "        else:\n",
    "            prefix = prefix[-self.n + 1:]\n",
    "        possible_ends = self.ngrams[tuple(prefix)]\n",
    "        sum_freq = np.log(sum(possible_ends[e] for e in possible_ends))\n",
    "        return {e: np.log(possible_ends[e]) - sum_freq for e in possible_ends}\n",
    "    \n",
    "    def sample(self, prefix):\n",
    "        possible_ends = self.get_log_probs(prefix)\n",
    "        if len(possible_ends) > 0:\n",
    "            end = np.random.choice(list(possible_ends.keys()), p=np.exp(list(possible_ends.values())))\n",
    "            return end\n",
    "        return EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим 5-граммную модель и посмотрим, как хорошо справляется она с генерацией текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "frigram = NGramModel(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b8aa030f07424ab8fd28631861d730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frigram.compute_ngrams(train_dataset, dataset.tokenize_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'программист_NOUN': -4.899873009733009,\n",
       " 'завод_NOUN': -5.68833037009728,\n",
       " 'автомобиль_NOUN': -5.68833037009728,\n",
       " 'управление_NOUN': -4.302036008977389,\n",
       " 'главное_NOUN': -6.19915599386327,\n",
       " 'центр_NOUN': -4.812861632743379,\n",
       " 'ввс_NOUN': -5.218326740851545,\n",
       " 'компания_NOUN': -1.5906580177825047,\n",
       " 'организация_NOUN': -5.351858133476067,\n",
       " 'армения_NOUN': -7.29776828253138,\n",
       " 'зоолог_NOUN': -5.911473921411489,\n",
       " 'орбита_NOUN': -7.29776828253138,\n",
       " 'археолог_NOUN': -3.4059479844207536,\n",
       " 'помощник_NOUN': -6.604621101971435,\n",
       " 'конференция_NOUN': -6.604621101971435,\n",
       " 'сша_NOUN': -5.68833037009728,\n",
       " 'технология_NOUN': -7.29776828253138,\n",
       " 'павел_NOUN': -7.29776828253138,\n",
       " 'министерство_NOUN': -4.658710952916122,\n",
       " 'исследователь_NOUN': -3.3465245639499526,\n",
       " 'великобритания_NOUN': -6.604621101971435,\n",
       " 'коллектив_NOUN': -7.29776828253138,\n",
       " 'проведение_NOUN': -7.29776828253138,\n",
       " 'время_NOUN': -4.995183189537334,\n",
       " 'программа_NOUN': -6.19915599386327,\n",
       " 'специалист_NOUN': -3.9655637723561763,\n",
       " 'холдинг_NOUN': -6.604621101971435,\n",
       " 'университет_NOUN': -4.35332930336494,\n",
       " 'американец_NOUN': -5.100543705195161,\n",
       " 'июль_NOUN': -6.19915599386327,\n",
       " 'серия_NOUN': -6.604621101971435,\n",
       " 'стартап_NOUN': -5.100543705195161,\n",
       " 'сказка_NOUN': -7.29776828253138,\n",
       " 'павильон_NOUN': -7.29776828253138,\n",
       " 'скорость_NOUN': -7.29776828253138,\n",
       " 'пользователь_NOUN': -4.812861632743379,\n",
       " 'разработчик_NOUN': -4.812861632743379,\n",
       " 'сенат_NOUN': -7.29776828253138,\n",
       " 'физик_NOUN': -6.19915599386327,\n",
       " 'поиск_NOUN': -7.29776828253138,\n",
       " 'расследование_NOUN': -7.29776828253138,\n",
       " 'обновление_NOUN': -5.68833037009728,\n",
       " 'эмират_NOUN': -7.29776828253138,\n",
       " 'военный_NOUN': -5.911473921411489,\n",
       " 'автопроизводитель_NOUN': -5.218326740851545,\n",
       " 'читать_VERB': -6.19915599386327,\n",
       " 'правительство_NOUN': -5.911473921411489,\n",
       " 'версия_NOUN': -5.506008813303325,\n",
       " 'смоделировать_VERB': -7.29776828253138,\n",
       " 'поисковик_NOUN': -7.29776828253138,\n",
       " 'студент_NOUN': -5.68833037009728,\n",
       " 'корабль_NOUN': -4.995183189537334,\n",
       " 'экспедиция_NOUN': -7.29776828253138,\n",
       " 'институт_NOUN': -4.5897180814291705,\n",
       " 'вмс_NOUN': -5.218326740851545,\n",
       " 'агентство_NOUN': -4.35332930336494,\n",
       " 'обсерватория_NOUN': -5.911473921411489,\n",
       " 'изобретатель_NOUN': -5.351858133476067,\n",
       " 'страна_NOUN': -6.604621101971435,\n",
       " 'совладелец_NOUN': -7.29776828253138,\n",
       " 'арсенал_NOUN': -6.604621101971435,\n",
       " 'создатель_NOUN': -6.19915599386327,\n",
       " 'студия_NOUN': -6.19915599386327,\n",
       " 'стартовать_VERB': -5.911473921411489,\n",
       " 'группа_NOUN': -3.5365681668378177,\n",
       " 'снимка_NOUN': -6.19915599386327,\n",
       " 'команда_NOUN': -4.995183189537334,\n",
       " 'китай_NOUN': -6.19915599386327,\n",
       " 'россия_NOUN': -5.68833037009728,\n",
       " 'секретарь_NOUN': -6.604621101971435,\n",
       " 'смартфон_NOUN': -6.19915599386327,\n",
       " 'фильм_NOUN': -7.29776828253138,\n",
       " 'партия_NOUN': -7.29776828253138,\n",
       " 'командование_NOUN': -5.218326740851545,\n",
       " 'истребитель_NOUN': -5.351858133476067,\n",
       " 'биолог_NOUN': -5.68833037009728,\n",
       " 'приложение_NOUN': -5.100543705195161,\n",
       " 'департамент_NOUN': -6.604621101971435,\n",
       " 'вывод_NOUN': -5.911473921411489,\n",
       " 'ракета_NOUN': -5.100543705195161,\n",
       " 'англичанин_NOUN': -7.29776828253138,\n",
       " 'предприятие_NOUN': -6.19915599386327,\n",
       " 'сообщество_NOUN': -7.29776828253138,\n",
       " 'ожирение_NOUN': -7.29776828253138,\n",
       " 'сан_NOUN': -7.29776828253138,\n",
       " 'наблюдать_VERB': -7.29776828253138,\n",
       " 'аппарат_NOUN': -4.525179560291599,\n",
       " 'мореплаватель_NOUN': -7.29776828253138,\n",
       " 'фотограф_NOUN': -5.911473921411489,\n",
       " 'реставратор_NOUN': -7.29776828253138,\n",
       " 'фирма_NOUN': -7.29776828253138,\n",
       " 'парк_NOUN': -7.29776828253138,\n",
       " 'академия_NOUN': -6.604621101971435,\n",
       " 'запуск_NOUN': -7.29776828253138,\n",
       " 'врач_NOUN': -6.604621101971435,\n",
       " 'полиция_NOUN': -7.29776828253138,\n",
       " 'союз_NOUN': -7.29776828253138,\n",
       " 'концерн_NOUN': -4.899873009733009,\n",
       " 'храм_NOUN': -7.29776828253138,\n",
       " 'аллен_NOUN': -7.29776828253138,\n",
       " 'як_NOUN': -7.29776828253138,\n",
       " 'дизайнер_NOUN': -5.68833037009728,\n",
       " 'панорама_NOUN': -5.911473921411489,\n",
       " 'мэтт_NOUN': -7.29776828253138,\n",
       " 'частица_NOUN': -7.29776828253138,\n",
       " 'привязка_NOUN': -7.29776828253138,\n",
       " 'батарея_NOUN': -5.351858133476067,\n",
       " 'дизайн_NOUN': -7.29776828253138,\n",
       " 'сотрудник_NOUN': -4.899873009733009,\n",
       " 'электроэнцефалограф_NOUN': -7.29776828253138,\n",
       " 'объявить_VERB': -5.911473921411489,\n",
       " 'художник_NOUN': -6.19915599386327,\n",
       " 'собираться_VERB': -7.29776828253138,\n",
       " 'магазин_NOUN': -7.29776828253138,\n",
       " 'возможность_NOUN': -7.29776828253138,\n",
       " 'комиссия_NOUN': -6.604621101971435,\n",
       " 'лауреат_NOUN': -6.19915599386327,\n",
       " 'июнь_NOUN': -6.19915599386327,\n",
       " 'профессор_NOUN': -7.29776828253138,\n",
       " 'кристина_NOUN': -7.29776828253138,\n",
       " 'система_NOUN': -5.351858133476067,\n",
       " 'покупатель_NOUN': -7.29776828253138,\n",
       " 'рамка_NOUN': -5.351858133476067,\n",
       " 'бизнесмен_NOUN': -7.29776828253138,\n",
       " 'сайт_NOUN': -5.100543705195161,\n",
       " 'банк_NOUN': -7.29776828253138,\n",
       " 'коллайдер_NOUN': -7.29776828253138,\n",
       " 'зоопарк_NOUN': -7.29776828253138,\n",
       " 'совершить_VERB': -6.604621101971435,\n",
       " 'день_NOUN': -7.29776828253138,\n",
       " 'телекомпания_NOUN': -7.29776828253138,\n",
       " 'фонд_NOUN': -6.604621101971435,\n",
       " 'инженер_NOUN': -4.253245844807957,\n",
       " 'отделение_NOUN': -7.29776828253138,\n",
       " 'воздействие_NOUN': -7.29776828253138,\n",
       " 'авиасалон_NOUN': -7.29776828253138,\n",
       " 'дочка_NOUN': -7.29776828253138,\n",
       " 'предположение_NOUN': -7.29776828253138,\n",
       " 'бортинженер_NOUN': -7.29776828253138,\n",
       " 'психолог_NOUN': -5.68833037009728,\n",
       " 'начало_NOUN': -6.19915599386327,\n",
       " 'обеспечение_NOUN': -7.29776828253138,\n",
       " 'спутник_NOUN': -6.19915599386327,\n",
       " 'робот_NOUN': -6.19915599386327,\n",
       " 'робототехника_NOUN': -7.29776828253138,\n",
       " 'чтение_NOUN': -7.29776828253138,\n",
       " 'корпорация_NOUN': -4.407396524635216,\n",
       " 'анимация_NOUN': -6.604621101971435,\n",
       " 'моделист_NOUN': -7.29776828253138,\n",
       " 'проект_NOUN': -5.218326740851545,\n",
       " 'трансляция_NOUN': -5.68833037009728,\n",
       " 'расширение_NOUN': -7.29776828253138,\n",
       " 'представить_VERB': -5.68833037009728,\n",
       " 'британия_NOUN': -7.29776828253138,\n",
       " 'сеть_NOUN': -5.506008813303325,\n",
       " 'гвардия_NOUN': -7.29776828253138,\n",
       " 'суд_NOUN': -6.604621101971435,\n",
       " 'представитель_NOUN': -5.506008813303325,\n",
       " 'качество_NOUN': -6.19915599386327,\n",
       " 'стыковка_NOUN': -7.29776828253138,\n",
       " 'сила_NOUN': -6.604621101971435,\n",
       " 'побережье_NOUN': -7.29776828253138,\n",
       " 'канадец_NOUN': -6.19915599386327,\n",
       " 'реструктуризация_NOUN': -7.29776828253138,\n",
       " 'эксперимент_NOUN': -7.29776828253138,\n",
       " 'космодром_NOUN': -7.29776828253138,\n",
       " 'палеонтолог_NOUN': -6.19915599386327,\n",
       " 'перенести_VERB': -7.29776828253138,\n",
       " 'беспилотник_NOUN': -6.19915599386327,\n",
       " 'октябрь_NOUN': -7.29776828253138,\n",
       " 'сми_NOUN': -7.29776828253138,\n",
       " 'школа_NOUN': -6.604621101971435,\n",
       " 'космонавт_NOUN': -6.604621101971435,\n",
       " 'лаборатория_NOUN': -5.506008813303325,\n",
       " 'подразделение_NOUN': -5.506008813303325,\n",
       " 'данные_NOUN': -7.29776828253138,\n",
       " 'оператор_NOUN': -5.911473921411489,\n",
       " 'служба_NOUN': -5.911473921411489,\n",
       " 'осьминог_NOUN': -7.29776828253138,\n",
       " 'сервис_NOUN': -5.911473921411489,\n",
       " 'яндекс_NOUN': -6.19915599386327,\n",
       " 'бета_NOUN': -6.19915599386327,\n",
       " 'производитель_NOUN': -5.911473921411489,\n",
       " 'пакет_NOUN': -7.29776828253138,\n",
       " 'тест_NOUN': -7.29776828253138,\n",
       " 'условие_NOUN': -7.29776828253138,\n",
       " 'попытка_NOUN': -6.19915599386327,\n",
       " 'проанализировать_VERB': -7.29776828253138,\n",
       " 'выпускник_NOUN': -7.29776828253138,\n",
       " 'платформа_NOUN': -5.218326740851545,\n",
       " 'илона_NOUN': -6.604621101971435,\n",
       " 'исследовать_VERB': -6.604621101971435,\n",
       " 'астроном_NOUN': -6.19915599386327,\n",
       " 'марс_NOUN': -7.29776828253138,\n",
       " 'ступень_NOUN': -6.604621101971435,\n",
       " 'крыша_NOUN': -7.29776828253138,\n",
       " 'эйтан_NOUN': -7.29776828253138,\n",
       " 'интернет_NOUN': -7.29776828253138,\n",
       " 'социолог_NOUN': -6.604621101971435,\n",
       " 'кампания_NOUN': -7.29776828253138,\n",
       " 'бюро_NOUN': -7.29776828253138,\n",
       " 'требование_NOUN': -7.29776828253138,\n",
       " 'шлем_NOUN': -6.604621101971435,\n",
       " 'достижение_NOUN': -7.29776828253138,\n",
       " 'италия_NOUN': -7.29776828253138,\n",
       " 'дельфт_NOUN': -7.29776828253138,\n",
       " 'грузовик_NOUN': -7.29776828253138,\n",
       " 'пол_NOUN': -7.29776828253138,\n",
       " 'заражение_NOUN': -7.29776828253138,\n",
       " 'сообщение_NOUN': -7.29776828253138,\n",
       " 'тройка_NOUN': -7.29776828253138,\n",
       " 'консорциум_NOUN': -6.19915599386327,\n",
       " 'премьер_NOUN': -7.29776828253138,\n",
       " 'конкурс_NOUN': -7.29776828253138,\n",
       " 'модель_NOUN': -7.29776828253138,\n",
       " 'власть_NOUN': -5.911473921411489,\n",
       " 'мочь_VERB': -7.29776828253138,\n",
       " 'коста_NOUN': -7.29776828253138,\n",
       " 'теоретик_NOUN': -7.29776828253138,\n",
       " 'комплекс_NOUN': -7.29776828253138,\n",
       " 'сообщать_VERB': -7.29776828253138,\n",
       " 'музей_NOUN': -7.29776828253138,\n",
       " 'историк_NOUN': -7.29776828253138,\n",
       " 'руководство_NOUN': -6.19915599386327,\n",
       " 'рейнджер_NOUN': -7.29776828253138,\n",
       " 'издание_NOUN': -7.29776828253138,\n",
       " 'раскопка_NOUN': -5.911473921411489,\n",
       " 'галерея_NOUN': -7.29776828253138,\n",
       " 'армия_NOUN': -7.29776828253138,\n",
       " 'файл_NOUN': -7.29776828253138,\n",
       " 'эксперт_NOUN': -7.29776828253138,\n",
       " 'зонд_NOUN': -6.604621101971435,\n",
       " 'номенклатура_NOUN': -7.29776828253138,\n",
       " 'предоставить_VERB': -7.29776828253138,\n",
       " 'физика_NOUN': -7.29776828253138,\n",
       " 'инвестор_NOUN': -7.29776828253138,\n",
       " 'этап_NOUN': -7.29776828253138,\n",
       " 'орган_NOUN': -7.29776828253138,\n",
       " 'томас_NOUN': -6.604621101971435,\n",
       " 'тая_NOUN': -7.29776828253138,\n",
       " 'винс_NOUN': -7.29776828253138,\n",
       " 'мозаика_NOUN': -7.29776828253138,\n",
       " 'помогать_VERB': -7.29776828253138,\n",
       " 'эндрю_NOUN': -7.29776828253138,\n",
       " 'япония_NOUN': -7.29776828253138,\n",
       " 'легализация_NOUN': -7.29776828253138,\n",
       " 'школьник_NOUN': -7.29776828253138,\n",
       " 'хаббл_NOUN': -7.29776828253138,\n",
       " 'участок_NOUN': -6.19915599386327,\n",
       " 'путешественник_NOUN': -7.29776828253138,\n",
       " 'поместье_NOUN': -7.29776828253138,\n",
       " 'канал_NOUN': -7.29776828253138,\n",
       " 'старт_NOUN': -6.19915599386327,\n",
       " 'снайпер_NOUN': -7.29776828253138,\n",
       " 'доступ_NOUN': -6.604621101971435,\n",
       " 'хирург_NOUN': -6.604621101971435,\n",
       " 'атака_NOUN': -7.29776828253138,\n",
       " 'шифрование_NOUN': -7.29776828253138,\n",
       " 'микробиолог_NOUN': -7.29776828253138,\n",
       " 'папирус_NOUN': -7.29776828253138,\n",
       " 'камера_NOUN': -7.29776828253138,\n",
       " 'работник_NOUN': -7.29776828253138,\n",
       " 'мосгордума_NOUN': -7.29776828253138,\n",
       " 'пресс_NOUN': -6.604621101971435,\n",
       " 'ботаник_NOUN': -6.604621101971435,\n",
       " 'станция_NOUN': -6.19915599386327,\n",
       " 'резинка_NOUN': -7.29776828253138,\n",
       " 'джозеф_NOUN': -7.29776828253138,\n",
       " 'аэропорт_NOUN': -7.29776828253138,\n",
       " 'описать_VERB': -6.604621101971435,\n",
       " 'город_NOUN': -6.604621101971435,\n",
       " 'эсминец_NOUN': -6.604621101971435,\n",
       " 'поколение_NOUN': -7.29776828253138,\n",
       " 'полицейский_NOUN': -7.29776828253138,\n",
       " 'вид_NOUN': -7.29776828253138,\n",
       " 'соединить_VERB': -7.29776828253138,\n",
       " 'назначение_NOUN': -7.29776828253138,\n",
       " 'окаменелость_NOUN': -7.29776828253138,\n",
       " 'коллекционер_NOUN': -7.29776828253138,\n",
       " 'пациент_NOUN': -7.29776828253138,\n",
       " 'москва_NOUN': -6.19915599386327,\n",
       " 'директор_NOUN': -7.29776828253138,\n",
       " 'подросток_NOUN': -7.29776828253138,\n",
       " 'безопасность_NOUN': -7.29776828253138,\n",
       " 'автор_NOUN': -7.29776828253138,\n",
       " 'деревня_NOUN': -7.29776828253138,\n",
       " 'игра_NOUN': -7.29776828253138,\n",
       " 'твиттер_NOUN': -7.29776828253138,\n",
       " 'дэвид_NOUN': -7.29776828253138,\n",
       " 'марк_NOUN': -7.29776828253138,\n",
       " 'исправление_NOUN': -7.29776828253138,\n",
       " 'пешеход_NOUN': -7.29776828253138,\n",
       " 'журналист_NOUN': -7.29776828253138,\n",
       " 'дания_NOUN': -7.29776828253138,\n",
       " 'материал_NOUN': -7.29776828253138,\n",
       " 'облако_NOUN': -7.29776828253138,\n",
       " 'журнал_NOUN': -6.604621101971435,\n",
       " 'провести_VERB': -6.604621101971435,\n",
       " 'дизель_NOUN': -7.29776828253138,\n",
       " 'сергей_NOUN': -7.29776828253138,\n",
       " 'фотография_NOUN': -7.29776828253138,\n",
       " 'математика_NOUN': -7.29776828253138,\n",
       " 'исследовательница_NOUN': -7.29776828253138,\n",
       " 'скотт_NOUN': -7.29776828253138,\n",
       " 'участник_NOUN': -6.604621101971435,\n",
       " 'преддверие_NOUN': -6.604621101971435,\n",
       " 'орнитолог_NOUN': -6.604621101971435,\n",
       " 'чили_NOUN': -7.29776828253138,\n",
       " 'бундесрат_NOUN': -7.29776828253138,\n",
       " 'успешность_NOUN': -7.29776828253138,\n",
       " 'госпиталь_NOUN': -7.29776828253138,\n",
       " 'километр_NOUN': -7.29776828253138,\n",
       " 'женщина_NOUN': -7.29776828253138,\n",
       " 'проигрыватель_NOUN': -7.29776828253138,\n",
       " 'продажа_NOUN': -6.604621101971435,\n",
       " 'обеспокоиться_VERB': -7.29776828253138,\n",
       " 'май_NOUN': -6.604621101971435,\n",
       " 'австралиец_NOUN': -7.29776828253138,\n",
       " 'экран_NOUN': -7.29776828253138,\n",
       " 'миссия_NOUN': -7.29776828253138,\n",
       " 'бельгия_NOUN': -7.29776828253138,\n",
       " 'стандарт_NOUN': -7.29776828253138,\n",
       " 'венерин_NOUN': -7.29776828253138,\n",
       " 'игрушка_NOUN': -7.29776828253138,\n",
       " 'функция_NOUN': -6.604621101971435,\n",
       " 'диорама_NOUN': -7.29776828253138,\n",
       " 'лига_NOUN': -7.29776828253138,\n",
       " 'бразилия_NOUN': -7.29776828253138,\n",
       " 'госдума_NOUN': -7.29776828253138,\n",
       " 'фестиваль_NOUN': -7.29776828253138,\n",
       " 'работа_NOUN': -7.29776828253138,\n",
       " 'отдел_NOUN': -6.604621101971435,\n",
       " 'препарат_NOUN': -7.29776828253138,\n",
       " 'таиланд_NOUN': -7.29776828253138,\n",
       " 'выведение_NOUN': -7.29776828253138,\n",
       " 'основатель_NOUN': -6.604621101971435,\n",
       " 'портал_NOUN': -7.29776828253138,\n",
       " 'ген_NOUN': -7.29776828253138,\n",
       " 'публикация_NOUN': -7.29776828253138,\n",
       " 'редактор_NOUN': -7.29776828253138,\n",
       " 'появиться_VERB': -6.604621101971435,\n",
       " 'владелец_NOUN': -7.29776828253138,\n",
       " 'видео_NOUN': -7.29776828253138,\n",
       " 'фермер_NOUN': -7.29776828253138,\n",
       " 'польша_NOUN': -7.29776828253138,\n",
       " 'телеканал_NOUN': -6.604621101971435,\n",
       " 'мэр_NOUN': -7.29776828253138,\n",
       " 'вмф_NOUN': -6.604621101971435,\n",
       " 'прах_NOUN': -7.29776828253138,\n",
       " 'организатор_NOUN': -6.604621101971435,\n",
       " 'просмотр_NOUN': -7.29776828253138,\n",
       " 'причина_NOUN': -7.29776828253138,\n",
       " 'симона_NOUN': -7.29776828253138,\n",
       " 'самка_NOUN': -7.29776828253138,\n",
       " 'норвегия_NOUN': -7.29776828253138,\n",
       " 'корея_NOUN': -7.29776828253138,\n",
       " 'мгу_NOUN': -6.604621101971435,\n",
       " 'земля_NOUN': -7.29776828253138,\n",
       " 'камелот_NOUN': -7.29776828253138,\n",
       " 'кабель_NOUN': -7.29776828253138,\n",
       " 'мир_NOUN': -7.29776828253138,\n",
       " 'испания_NOUN': -7.29776828253138,\n",
       " 'комплект_NOUN': -7.29776828253138,\n",
       " 'администрация_NOUN': -7.29776828253138,\n",
       " 'альпинист_NOUN': -7.29776828253138,\n",
       " 'брайан_NOUN': -7.29776828253138,\n",
       " 'дейв_NOUN': -7.29776828253138,\n",
       " 'штурвал_NOUN': -7.29776828253138,\n",
       " 'снимок_NOUN': -6.604621101971435,\n",
       " 'кроссовер_NOUN': -7.29776828253138,\n",
       " 'глава_NOUN': -7.29776828253138,\n",
       " 'сон_NOUN': -7.29776828253138,\n",
       " 'учитель_NOUN': -7.29776828253138,\n",
       " 'спасатель_NOUN': -7.29776828253138,\n",
       " 'гаджет_NOUN': -7.29776828253138,\n",
       " 'пятница_NOUN': -7.29776828253138,\n",
       " 'калифорния_NOUN': -7.29776828253138,\n",
       " 'солитер_NOUN': -7.29776828253138,\n",
       " 'пехота_NOUN': -7.29776828253138,\n",
       " 'швейцарец_NOUN': -7.29776828253138,\n",
       " 'разработка_NOUN': -7.29776828253138,\n",
       " 'энтузиаст_NOUN': -7.29776828253138,\n",
       " 'час_NOUN': -7.29776828253138,\n",
       " 'покров_NOUN': -7.29776828253138,\n",
       " 'госкомпания_NOUN': -7.29776828253138,\n",
       " 'копия_NOUN': -7.29776828253138,\n",
       " 'дэйв_NOUN': -7.29776828253138,\n",
       " 'раунд_NOUN': -7.29776828253138,\n",
       " 'вакцинация_NOUN': -7.29776828253138,\n",
       " 'популярность_NOUN': -7.29776828253138,\n",
       " 'траулер_NOUN': -7.29776828253138,\n",
       " 'помощь_NOUN': -7.29776828253138,\n",
       " 'житель_NOUN': -7.29776828253138,\n",
       " 'геофизик_NOUN': -7.29776828253138,\n",
       " 'германия_NOUN': -6.604621101971435,\n",
       " 'ирландец_NOUN': -7.29776828253138,\n",
       " 'количество_NOUN': -7.29776828253138,\n",
       " 'сотрудница_NOUN': -7.29776828253138,\n",
       " 'годовщина_NOUN': -7.29776828253138,\n",
       " 'аспирант_NOUN': -7.29776828253138,\n",
       " 'американка_NOUN': -7.29776828253138,\n",
       " 'практика_NOUN': -7.29776828253138,\n",
       " 'роспотребнадзор_NOUN': -7.29776828253138,\n",
       " 'вера_NOUN': -7.29776828253138,\n",
       " 'карта_NOUN': -7.29776828253138,\n",
       " 'пожарный_NOUN': -7.29776828253138,\n",
       " 'руководитель_NOUN': -7.29776828253138,\n",
       " 'активность_NOUN': -7.29776828253138,\n",
       " 'территория_NOUN': -7.29776828253138,\n",
       " 'роскосмос_NOUN': -7.29776828253138,\n",
       " 'лингвист_NOUN': -7.29776828253138,\n",
       " 'телескоп_NOUN': -7.29776828253138,\n",
       " 'изображение_NOUN': -7.29776828253138,\n",
       " 'компонент_NOUN': -7.29776828253138,\n",
       " 'мумия_NOUN': -7.29776828253138,\n",
       " 'авиакомпания_NOUN': -7.29776828253138,\n",
       " 'кина_NOUN': -7.29776828253138,\n",
       " 'исследование_NOUN': -7.29776828253138,\n",
       " 'командующий_NOUN': -7.29776828253138,\n",
       " 'компьютер_NOUN': -7.29776828253138,\n",
       " 'агенство_NOUN': -7.29776828253138,\n",
       " 'цветок_NOUN': -7.29776828253138,\n",
       " 'ряд_NOUN': -7.29776828253138,\n",
       " 'промышленность_NOUN': -7.29776828253138,\n",
       " 'курение_NOUN': -7.29776828253138,\n",
       " 'экипаж_NOUN': -7.29776828253138,\n",
       " 'австралия_NOUN': -7.29776828253138,\n",
       " 'преподаватель_NOUN': -7.29776828253138,\n",
       " 'флот_NOUN': -7.29776828253138,\n",
       " 'электромобиль_NOUN': -7.29776828253138,\n",
       " 'ноябрь_NOUN': -7.29776828253138,\n",
       " 'регистрация_NOUN': -7.29776828253138,\n",
       " 'смерть_NOUN': -7.29776828253138,\n",
       " 'дорога_NOUN': -7.29776828253138,\n",
       " 'окрестность_NOUN': -7.29776828253138,\n",
       " 'крейсер_NOUN': -7.29776828253138,\n",
       " 'цвет_NOUN': -7.29776828253138,\n",
       " 'порт_NOUN': -7.29776828253138,\n",
       " 'верфь_NOUN': -7.29776828253138,\n",
       " 'распространение_NOUN': -7.29776828253138,\n",
       " 'пара_NOUN': -7.29776828253138}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frigram.get_log_probs(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'шеффилд_NOUN'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frigram.sample(\"университет\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, prefix, length=100):\n",
    "    text = \"\" + prefix\n",
    "    while len(text) < length:\n",
    "        token = model.sample(text)\n",
    "        text += \" \" + token\n",
    "        if token < EOS:\n",
    "            break\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' британия_NOUN фотограф_NOUN компания_NOUN компания_NOUN компания_NOUN станция_NOUN реставратор_NOUN'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(frigram, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количественная величина, которая позволяет сравнивать LM: перплекция. Для её вычисления используется следующая формула:\n",
    "\n",
    "$$\n",
    "\\text{Ppr} = \\exp^{\\frac{1}{|D|} \\sum_{t \\in D}\\sum_{w \\in t} - \\log (p(w))},\n",
    "$$\n",
    "где $D$ – валидационный датасет, $|D|$ – общая длина текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_ngram(dataset, model):\n",
    "    lengths = 0\n",
    "    log_prob = 0\n",
    "    for row in tqdm(dataset):\n",
    "        tokens = row[\"tokens\"]\n",
    "        lengths += len(tokens)\n",
    "        ngram = [PAD] * model.n\n",
    "        for token in tokens:\n",
    "            ngram[:-1] = ngram[1:]\n",
    "            ngram[-1] = token\n",
    "            log_prob += model.get_log_probs(ngram[:-1]).get(ngram[-1], -15)\n",
    "    return np.exp(-log_prob / lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80ae6c883764cc2b29c7552abf3b3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=369.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1759708.2315360727"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_ngram(valid_dataset, frigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NN LM\n",
    "\n",
    "Приступим к нейросетевым языковым моделям. Для начала нам потребуется сэмплер из прошлого семинара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "\n",
    "\n",
    "class TextSampler(Sampler):\n",
    "    def __init__(self, sampler, batch_size_tokens=1e4):\n",
    "        self.sampler = sampler\n",
    "        self.batch_size_tokens = batch_size_tokens\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch = []\n",
    "        max_len = 0\n",
    "        for ix in self.sampler:\n",
    "            row = self.sampler.data_source[ix]\n",
    "            max_len = max(max_len, len(row[\"input_ids\"]))\n",
    "            if (len(batch) + 1) * max_len > self.batch_size_tokens:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                max_len = len(row[\"input_ids\"])\n",
    "            batch.append(ix)\n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    max_len = max(len(row[\"input_ids\"]) for row in batch)\n",
    "    input_embeds = np.zeros((len(batch), max_len))\n",
    "    for idx, row in enumerate(batch):\n",
    "        input_embeds[idx][:len(row[\"input_ids\"])] += row[\"input_ids\"]\n",
    "    row[\"input_ids\"] = torch.LongTensor(input_embeds)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, random_split\n",
    "\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=TextSampler(train_sampler), collate_fn=collate_fn, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_sampler=TextSampler(valid_sampler), collate_fn=collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "Вторая жертва – CNN. Если внимательно посмотреть, то она является нейросетевым приближением к n-грамной модели. Для её реализации нам потребуется новым модуль – `nn.ZeroPad2d`[docs](https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad2d.html). Он добавит нулей в нужном месте, чтобы конволюционный слой смотрел только на предыдущие токены при предсказании текущего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNNLM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.pad = nn.ZeroPad2d((4, 0, 0, 0))\n",
    "        self.conv = nn.Conv1d(emb_size, hidden_size, kernel_size=5)\n",
    "        self.pred = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        embed = self.emb(input_ids).permute(0, 2, 1)\n",
    "        padded = self.pad(embed)\n",
    "        convolved = torch.relu(self.conv(padded)).permute(0, 2, 1)\n",
    "        return self.pred(convolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNNLM(len(dataset.vocab) + 4, 300, 100).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.token2idx[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(self):\n",
    "    w = torch.rand(len(self.vocab) + 4, word2vec.vector_size)\n",
    "    for token, num in self.token2idx.items():\n",
    "        if token in word2vec:\n",
    "            w[num] = torch.from_numpy(word2vec[token])\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.emb.weight.copy_(embeddings(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a9d7573dfe4413a14615ee9d9059cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Loss: 7.620480060577393, Valid Peprplexity: 2039.5408935546875\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "\n",
    "            prediction = model(input_ids[:, :-1])\n",
    "            loss = criterion(\n",
    "                prediction.reshape(-1, prediction.size(-1)), \n",
    "                input_ids[:, 1:].reshape(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            # обучи модель \n",
    "\n",
    "            pbar.update(input_ids.size(0))\n",
    "        \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    n_iter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            n_iter += 1\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            prediction = model(input_ids[:, :-1])\n",
    "            valid_loss += criterion(prediction.reshape(-1, prediction.size(-1)), input_ids[:, 1:].reshape(-1))\n",
    "    print(f\"Valid Loss: {valid_loss / n_iter}, Valid Peprplexity: {torch.exp(valid_loss / n_iter)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения модели посмотрим, как она справляется с задачей генерации текста. Сделаем специальную функцию для этого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, prefix, max_length=100):\n",
    "    tokens = dataset.tokenize_(prefix)[:-1]\n",
    "    input_ids = [dataset.token2idx.get(token) for token in tokens]\n",
    "    input_ids_tensor = torch.LongTensor(input_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            output = model(input_ids_tensor)\n",
    "\n",
    "            probs = torch.softmax(output[:, -1].cpu(), -1).numpy()[0]\n",
    "            # получи из output вероятности следующего токена\n",
    "            next_id = np.random.choice(np.arange(len(dataset.vocab) + 4), p=probs)\n",
    "            # получи следующий токен\n",
    "            tokens += [dataset.idx2token[next_id]]\n",
    "            # добавь токен в список токенов\n",
    "            \n",
    "            if dataset.idx2token[next_id] == EOS or len(tokens) > max_length:\n",
    "                break\n",
    "            input_ids += [next_id]\n",
    "            input_ids_tensor = torch.LongTensor(input_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    return \" \".join(t.split(\"_\")[0] for t in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'университет пойти сочетание перстень местность шик хоббит подвергать штопор запись превышать камера дорога вилма сохранять мочь предел соединение тим окситоцин подскакивать сканирование вода мир глава тысяча лето ответ <EOS>'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "sample(model, \"университет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "\n",
    "Последняя жертва – LSTM. Она должна лучше работать с длинными текстами, потому что у неё нет фиксированного количества токенов, на которые она можеть \"смотреть\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMLM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "        # Сделай lstm слой\n",
    "        self.pred = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        embs = self.emb(input_ids)\n",
    "        output, _ = self.lstm(embs)\n",
    "        return self.pred(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LSTMLM(len(dataset.vocab) + 4, 300, 100).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.token2idx[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.emb.weight.copy_(embeddings(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85a15f033594b759299fbaa1f85c02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1477.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Loss: 7.757643699645996, Valid Peprplexity: 2339.385986328125\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "\n",
    "            prediction = model(input_ids[:, :-1])\n",
    "            loss = criterion(\n",
    "                prediction.reshape(-1, prediction.size(-1)), \n",
    "                input_ids[:, 1:].reshape(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            # обучи модель \n",
    "\n",
    "            pbar.update(input_ids.size(0))\n",
    "        \n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    n_iter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            n_iter += 1\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            prediction = model(input_ids[:, :-1])\n",
    "            valid_loss += criterion(prediction.reshape(-1, prediction.size(-1)), input_ids[:, 1:].reshape(-1))\n",
    "    print(f\"Valid Loss: {valid_loss / n_iter}, Valid Peprplexity: {torch.exp(valid_loss / n_iter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'университет сопровождаться динамика выстреливаться получить роскосмос время комета доллар астероид покров взаимодействие компания экран обитать штукатурка игра мкс проект элемент обеспечивать творение наведение фигурка услышать донор соя движение воронцов <EOS>'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "sample(model, \"университет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что дальше?\n",
    " \n",
    "Если мы говорим про генерацию, то модель надо обучать подольше и на большом количестве текста. Если хочешь поэкспериментировать с генерацией, то я предлагаю такой план:\n",
    " \n",
    "- обучи модель на всех новостях (min_diff=0, max_diff=10)\n",
    "- сохрани веса этой модели (torch.save(model.state_dict()))\n",
    "- переобучи несколько моделей на новостях с другими значениями сложности (eg. (min_diff=1, max_diff=3), (min_diff=4, max_diff=8))\n",
    "- сравни сгенерированные тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "charLM\n",
    "CNN(char) -> LSTM\n",
    "BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
